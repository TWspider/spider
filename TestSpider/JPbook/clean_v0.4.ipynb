{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba\n",
    "import difflib\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=create_engine('mssql+pymssql://tw_user:123456@10.55.5.215/TWSpider')\n",
    "# 取出my字段，roomid，小区，地址，区域--------（编号--小区id编号）\n",
    "extract_comm=pd.read_sql(\"select RoomId,HouseUrl,Floor,HouseType,BuildingSquare,HouseDirection,PropertyCommunity,PriceUnit,PropertyAddress,AreaName,HouseDesc,Resource,TotalFloor from ThirdHouseResource\",engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1(HouseDesc为空，使用PriceUnit填充(已查询特点))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1(HouseDesc为空，使用PriceUnit填充(已查询特点))\n",
    "for index,comm in enumerate(extract_comm['PropertyCommunity']):\n",
    "    if comm==None and extract_comm.loc[index,'HouseDesc']=='':\n",
    "        extract_comm.loc[index,'HouseDesc']=extract_comm.loc[index,'PriceUnit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 填补小区名（直接desc中提取--链家整租可以直接提取的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_discomm():\n",
    "    # 提取出所有小区名,作为停用词(小区+desc中提取的小区)\n",
    "    stop_word_comm=extract_comm['PropertyCommunity'].unique().tolist()\n",
    "    # 从desc中提取小区\n",
    "    ext_comm=[]\n",
    "    cond=extract_comm['PropertyCommunity'].isnull()\n",
    "    for desc in extract_comm[cond]['HouseDesc'].unique():\n",
    "        pattern=re.compile('.*?·(.*?)\\s')\n",
    "        res=pattern.findall(desc)\n",
    "        try:\n",
    "            ext_comm.append(res[0])\n",
    "        except:\n",
    "            ext_comm.append(desc)\n",
    "    # 将desc中提取的小区和直接取出的小区求交集\n",
    "    finally_comm=set()\n",
    "    for comm in ext_comm+stop_word_comm:\n",
    "        patt=re.compile('(.*?)[\\(\\（]')\n",
    "        try:\n",
    "    #         print(comm)\n",
    "            res=patt.findall(comm)\n",
    "            finally_comm.add(res[0])\n",
    "        except:\n",
    "            finally_comm.add(comm)\n",
    "    lj_total_comm=pd.DataFrame(data=finally_comm,columns=['comm'])\n",
    "    lj_total_comm.to_csv('1.csv',index=None)\n",
    "    # 将停用词文件读取出来，设置特定词语不被分开 \n",
    "    stop_word_set=set(pd.read_csv('./1.csv')['comm'].to_list())\n",
    "    # 加载自己的停用词典\n",
    "    jieba.load_userdict('1.csv')\n",
    "     # 调整词典，使特定的词语不被分开\n",
    "    for word in stop_word_set:\n",
    "        if word!=None:\n",
    "            jieba.suggest_freq(str(word), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_other(index,PropertyCommunity_list):\n",
    "    # 已经填补完desc，将小区为空的记录取出来\n",
    "    word_list=jieba.cut(extract_comm.loc[index,'HouseDesc'],cut_all=False,HMM=False)\n",
    "    PropertyCommunity_list.append(list(word_list)[0])\n",
    "#     print(list(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.730 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "c:\\users\\1\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "cond=extract_comm['PropertyCommunity'].isnull()\n",
    "PropertyCommunity_list=[]\n",
    "for index in extract_comm[cond].index:\n",
    "    desc=extract_comm.loc[index,'HouseDesc']\n",
    "    pattern=re.compile('(.*?)·(.*?)\\s')\n",
    "    res=pattern.findall(desc)\n",
    "    try:\n",
    "        #链家整租，直接提取\n",
    "        if res[0][0]=='整租':\n",
    "            PropertyCommunity_list.append(res[0][1])\n",
    "        else:\n",
    "            extract_other(index,PropertyCommunity_list)\n",
    "    except:\n",
    "        extract_other(index,PropertyCommunity_list)\n",
    "temp=extract_comm[cond]\n",
    "temp.loc[:,'PropertyCommunity']=pd.Series(data=PropertyCommunity_list).values\n",
    "temp_array=np.concatenate((extract_comm[extract_comm['PropertyCommunity'].notnull()].values,temp.values))\n",
    "extract_comm=pd.DataFrame(data=temp_array,columns=extract_comm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理面积，户型，地址字段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 面积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BuildingSquare_list=extract_comm['BuildingSquare'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 处理面积\n",
    "BuildingSquare=[]\n",
    "for square in BuildingSquare_list:\n",
    "    try:\n",
    "        res=re.split(\" |平米|㎡\",square)\n",
    "        BuildingSquare.append(res[0])\n",
    "    except:\n",
    "        BuildingSquare.append(None)\n",
    "#把面积替换掉\n",
    "if len(BuildingSquare)==extract_comm['BuildingSquare'].shape[0]:\n",
    "    extract_comm['BuildingSquare']=pd.Series(data=BuildingSquare)\n",
    "else:\n",
    "    print('上面出错，长度不够')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 户型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理户型.0是没有None是没有HouseType这个字段\n",
    "HouseType=extract_comm['HouseType']\n",
    "room_list=[]\n",
    "hall_list=[]\n",
    "toilet_list=[]\n",
    "for index,type_ in enumerate(HouseType):\n",
    "    try:\n",
    "        room=re.findall('(\\d+)室',type_)\n",
    "        if room==[]:\n",
    "            room_list.insert(index,0)\n",
    "        else:\n",
    "            room_list.insert(index,room[0])\n",
    "        \n",
    "        hall=re.findall('(\\d+)厅',type_)\n",
    "        if hall==[]:\n",
    "             hall_list.insert(index,0)\n",
    "        else:\n",
    "            hall_list.insert(index,hall[0])\n",
    "        \n",
    "        toilet=re.findall('(\\d+)卫',type_)\n",
    "        if toilet==[]:\n",
    "            toilet_list.insert(index,0)\n",
    "        else:\n",
    "            toilet_list.insert(index,toilet[0])\n",
    "    except:\n",
    "        #None\n",
    "        room_list.insert(index,None)\n",
    "        hall_list.insert(index,None)\n",
    "        toilet_list.insert(index,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加厅，室，卫，列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(room_list)==len(hall_list)==len(toilet_list)==extract_comm['HouseType'].shape[0]:\n",
    "    extract_comm['room']=pd.Series(data=room_list)\n",
    "    extract_comm['hall']=pd.Series(data=hall_list)\n",
    "    extract_comm['toilet']=pd.Series(data=toilet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理总层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TotalFloor_list=[]\n",
    "reg=re.compile('\\d+')\n",
    "for totalfloor in extract_comm['TotalFloor']:\n",
    "    try:\n",
    "        res=reg.findall(totalfloor)\n",
    "        if len(res)>0:\n",
    "            TotalFloor_list.append(res[0])\n",
    "        else:\n",
    "            TotalFloor_list.append(totalfloor)\n",
    "    except:\n",
    "        #None\n",
    "        TotalFloor_list.append(None)\n",
    "extract_comm['TotalFloor']=pd.Series(data=TotalFloor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305744, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_comm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匹配(小区或者地址)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 另一种方法，直接匹配地址（因为大量数据存在小区名一致，但是地址不一致的情况）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_Estate=create_engine('mssql+pymssql://tw_user:123456@10.55.5.7/TWEstate_S')\n",
    "#数据库数据\n",
    "sql_Estate=pd.read_sql('SELECT distinct EstateId,EstateAreaName,EstateAddress,EstateOtherAddress from Estate',engine_Estate)\n",
    "#爬取数据\n",
    "my_Estate=extract_comm.loc[:,['PropertyCommunity','AreaName','PropertyAddress','Resource','HouseDesc']]\n",
    "# 将sql_Estate所有''置换为nan\n",
    "index=sql_Estate.query(\"EstateAddress==''\").index\n",
    "sql_Estate.loc[index,['EstateAddress']]=np.nan\n",
    "index=sql_Estate.query(\"EstateAreaName==''\").index\n",
    "sql_Estate.loc[index,['EstateAreaName']]=np.nan\n",
    "# 将my_Estate所有''置换为nan\n",
    "index=my_Estate.query(\"PropertyCommunity==''\").index\n",
    "my_Estate.loc[index,['PropertyCommunity']]=np.nan\n",
    "index=my_Estate.query(\"PropertyAddress==''\").index\n",
    "my_Estate.loc[index,['PropertyAddress']]=np.nan\n",
    "#合并（以地址相同为条件）\n",
    "comm_mapping=sql_Estate[sql_Estate['EstateAddress'].notnull()].merge(my_Estate[my_Estate['PropertyAddress'].notnull()],how='inner',left_on='EstateAddress',right_on='PropertyAddress')\n",
    "comm_mapping.drop_duplicates(inplace=True)\n",
    "comm_mapping.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 地址没有匹配成功，且不存在地址的记录，直接匹配小区名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取没有匹配成功的记录\n",
    "not_mapping_set=set(my_Estate['PropertyAddress'].unique().tolist())-set(comm_mapping['PropertyAddress'].unique().tolist())\n",
    "not_mapping=pd.DataFrame(data=my_Estate.query(\"PropertyAddress in @not_mapping_set\").values,columns=my_Estate.columns)\n",
    "not_mapping.drop_duplicates(subset=['PropertyCommunity','PropertyAddress'],inplace=True)\n",
    "not_mapping.reset_index(drop=True,inplace=True)\n",
    "#取出地址为空的记录，直接对比小区（无地址）\n",
    "cond=not_mapping['PropertyAddress'].isnull()\n",
    "hasnot_addr=not_mapping[cond]\n",
    "merge_comm=sql_Estate.merge(hasnot_addr,how='inner',left_on='EstateAreaName',right_on='PropertyCommunity')\n",
    "merge_comm.drop_duplicates(keep='first',inplace=True)\n",
    "merge_comm.reset_index(drop=True,inplace=True)#  小区名直接相等\n",
    "#提取地址为空且小区名不直接相等的处理\n",
    "isnequal_set=set(hasnot_addr['PropertyCommunity'].unique().tolist())-set(merge_comm['PropertyCommunity'].unique().tolist())\n",
    "next_hander_comm=pd.DataFrame(data=hasnot_addr.query(\"PropertyCommunity in @isnequal_set\").values,columns=hasnot_addr.columns)\n",
    "next_hander_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# 处理一波小区带括号的，且没地址的\n",
    "sql_Estate_set=set(sql_Estate['EstateAreaName'].unique().tolist())\n",
    "reg=re.compile('^(.*?)[\\(\\（]')\n",
    "sql_temp_list=[]\n",
    "my_temp_list=[]\n",
    "for comm in next_hander_comm['PropertyCommunity'].unique():\n",
    "    try:\n",
    "        ext_comm=reg.findall(comm)[0]\n",
    "        if ext_comm in sql_Estate_set:\n",
    "            sql_temp_list.append(ext_comm)\n",
    "            my_temp_list.append(comm)\n",
    "    except:\n",
    "#         print('does not match')\n",
    "        pass\n",
    "comm_list=[]\n",
    "for i in range(len(sql_temp_list)):\n",
    "    sql_comm=sql_temp_list[i]\n",
    "    my_comm=my_temp_list[i]\n",
    "#     print(sql_comm,'==============',my_comm)\n",
    "    sql_record=sql_Estate.query(\"EstateAreaName == @sql_comm\")\n",
    "    my_record=next_hander_comm.query(\"PropertyCommunity == @my_comm\")\n",
    "    for s_record in sql_record.values:\n",
    "        for m_record in my_record.values:\n",
    "#             print(np.hstack((s_record,m_record)))\n",
    "            comm_list.append(np.hstack((s_record,m_record)))\n",
    "#匹配成功的小区\n",
    "df=pd.DataFrame(comm_list,columns=comm_mapping.columns)\n",
    "\n",
    "\n",
    "#处理没有地址--没有直接匹配成功小区--去掉括号没有匹配成功小区\n",
    "third_set=set(next_hander_comm['PropertyCommunity'].unique().tolist())-set(df['PropertyCommunity'].unique().tolist())\n",
    "third_comm=pd.DataFrame(data=next_hander_comm.query(\"PropertyCommunity in @third_set\").values,columns=next_hander_comm.columns)\n",
    "third_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# 小区名匹配地址（星级较高）\n",
    "comm_merge_addr=sql_Estate[sql_Estate['EstateAddress'].notnull()].merge(third_comm[third_comm['PropertyCommunity'].notnull()],how='inner',left_on='EstateAddress',right_on='PropertyCommunity')\n",
    "comm_merge_addr.drop_duplicates(inplace=True)\n",
    "comm_merge_addr.reset_index(drop=True,inplace=True) #482\n",
    "\n",
    "#--没有地址--不能直接匹配小区--不能去掉括号匹配小区--不能小区匹配地址\n",
    "fourth_set=set(third_comm['PropertyCommunity'].unique().tolist())-set(comm_merge_addr['PropertyCommunity'].unique().tolist())\n",
    "fourth_comm=pd.DataFrame(data=third_comm.query(\"PropertyCommunity in @fourth_set\").values,columns=third_comm.columns)\n",
    "fourth_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#将merge_comm，df，comm_merge_addr合并到comm_mapping中\n",
    "comm_mapping=pd.DataFrame(np.concatenate((merge_comm.values,df.values,comm_merge_addr.values,comm_mapping.values)),columns=merge_comm.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **************fourth_comm TODO**********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not_mapping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.not_mapping 中有地址的,但是地址描述为“距离地铁”，“内环”，“外环”，相当于没地址，进行小区匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond=not_mapping['PropertyAddress'].notnull()\n",
    "has_addr=not_mapping[cond]\n",
    "has_addr.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_list=[]\n",
    "for i in has_addr.index:\n",
    "    PropertyAddress=has_addr.loc[i,'PropertyAddress']\n",
    "    if ('距离地铁'in PropertyAddress) or ('中环' in PropertyAddress) or ('内环' in PropertyAddress) or ('外环' in PropertyAddress) or (('近' in PropertyAddress) and ('附近' not in PropertyAddress)):\n",
    "        useless_list.append(i)\n",
    "useless_addr=has_addr.iloc[useless_list]\n",
    "useless_addr.reset_index(drop=True,inplace=True)\n",
    "#地址有用的部分\n",
    "usefull_addr_set=set([i for i in has_addr.index])-set(useless_list)\n",
    "usefull_addr=has_addr.iloc[list(usefull_addr_set)]\n",
    "usefull_addr.reset_index(drop=True,inplace=True)\n",
    "#地址无效的进行小区匹配useless_addr\n",
    "merge_comm=sql_Estate.merge(useless_addr,how='inner',left_on='EstateAreaName',right_on='PropertyCommunity')\n",
    "merge_comm.drop_duplicates(keep='first',inplace=True)\n",
    "merge_comm.reset_index(drop=True,inplace=True)#  小区名直接相等\n",
    "\n",
    "#提取小区名不直接相等的处理\n",
    "isnequal_set=set(useless_addr['PropertyCommunity'].unique().tolist())-set(merge_comm['PropertyCommunity'].unique().tolist())\n",
    "next_hander_comm=pd.DataFrame(data=useless_addr.query(\"PropertyCommunity in @isnequal_set\").values,columns=useless_addr.columns)\n",
    "next_hander_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "# 处理一波小区带括号的\n",
    "sql_Estate_set=set(sql_Estate['EstateAreaName'].unique().tolist())\n",
    "reg=re.compile('^(.*?)[\\(\\（]')\n",
    "sql_temp_list=[]\n",
    "my_temp_list=[]\n",
    "for comm in next_hander_comm['PropertyCommunity'].unique():\n",
    "    try:\n",
    "        ext_comm=reg.findall(comm)[0]\n",
    "        if ext_comm in sql_Estate_set:\n",
    "            sql_temp_list.append(ext_comm)\n",
    "            my_temp_list.append(comm)\n",
    "    except:\n",
    "#         print('does not match')\n",
    "        pass\n",
    "comm_list=[]\n",
    "for i in range(len(sql_temp_list)):\n",
    "    sql_comm=sql_temp_list[i]\n",
    "    my_comm=my_temp_list[i]\n",
    "#     print(sql_comm,'==============',my_comm)\n",
    "    sql_record=sql_Estate.query(\"EstateAreaName == @sql_comm\")\n",
    "    my_record=next_hander_comm.query(\"PropertyCommunity == @my_comm\")\n",
    "    for s_record in sql_record.values:\n",
    "        for m_record in my_record.values:\n",
    "#             print(np.hstack((s_record,m_record)))\n",
    "            comm_list.append(np.hstack((s_record,m_record)))\n",
    "#匹配成功的小区\n",
    "df=pd.DataFrame(comm_list,columns=comm_mapping.columns)\n",
    "\n",
    "#处理没有地址--没有直接匹配成功小区--去掉括号没有匹配成功小区\n",
    "third_set=set(next_hander_comm['PropertyCommunity'].unique().tolist())-set(df['PropertyCommunity'].unique().tolist())\n",
    "third_comm=pd.DataFrame(data=next_hander_comm.query(\"PropertyCommunity in @third_set\").values,columns=next_hander_comm.columns)\n",
    "third_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# 小区名匹配地址（星级较高）\n",
    "comm_merge_addr=sql_Estate[sql_Estate['EstateAddress'].notnull()].merge(third_comm[third_comm['PropertyCommunity'].notnull()],how='inner',left_on='EstateAddress',right_on='PropertyCommunity')\n",
    "comm_merge_addr.drop_duplicates(inplace=True)\n",
    "comm_merge_addr.reset_index(drop=True,inplace=True) #482\n",
    "\n",
    "#--没有地址--不能直接匹配小区--不能去掉括号匹配小区--不能小区匹配地址\n",
    "fourth_set=set(third_comm['PropertyCommunity'].unique().tolist())-set(comm_merge_addr['PropertyCommunity'].unique().tolist())\n",
    "fourth_comm=pd.DataFrame(data=third_comm.query(\"PropertyCommunity in @fourth_set\").values,columns=third_comm.columns)\n",
    "fourth_comm.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#将merge_comm，df，comm_merge_addr合并到comm_mapping中\n",
    "comm_mapping=pd.DataFrame(np.concatenate((merge_comm.values,df.values,comm_merge_addr.values,comm_mapping.values)),columns=merge_comm.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68339, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_mapping.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### not_mapping 中有效地址的进行处理--分成路和号和弄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usefull_addr\n",
    "jieba.load_userdict('sh.csv')\n",
    "shroad=set(pd.read_csv('sh.csv',header=None)[0].tolist())\n",
    "# 调整词典，使特定的词语不被分开\n",
    "for road in shroad:\n",
    "    if road!=None:\n",
    "        jieba.suggest_freq(str(road), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_road(word_list):\n",
    "    flag=0\n",
    "    word_set=set()\n",
    "    for word in word_list:\n",
    "        if word in shroad:\n",
    "            flag=1\n",
    "            word_set.add(word)\n",
    "    word_str=','.join(word_set)\n",
    "    return flag,word_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "road_list=[]\n",
    "for addr in usefull_addr['PropertyAddress']:\n",
    "    word_list=list(jieba.cut(addr,cut_all=False,HMM=False))\n",
    "    flag,word_str=add_road(word_list)\n",
    "    if flag==1:\n",
    "        road_list.append(word_str)\n",
    "    else:\n",
    "        #非路号，而是小区\n",
    "#         print(addr)\n",
    "        try:\n",
    "            road_list.append(None)\n",
    "        except:\n",
    "            road_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\1\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "usefull_addr['road']=pd.Series(data=road_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\1\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "alley_list=[]\n",
    "reg=re.compile('\\d+')\n",
    "for addr in usefull_addr['PropertyAddress']:\n",
    "        res=reg.findall(addr)\n",
    "        if len(res)>0:\n",
    "            alley=','.join(res)\n",
    "            alley_list.append(alley)\n",
    "        else:\n",
    "            alley_list.append(None)\n",
    "usefull_addr['alley']=pd.Series(data=alley_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只能执行一次  不然数组会过大\n",
    "usefull_addr=usefull_addr.drop('alley', axis=1).join(\n",
    "    usefull_addr['alley'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('alley'))\n",
    "\n",
    "usefull_addr=usefull_addr.drop('road', axis=1).join(\n",
    "    usefull_addr['road'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('road'))\n",
    "usefull_addr['road_']=usefull_addr['road']+usefull_addr['alley']\n",
    "usefull_addr.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefull_addr.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据库中的数据，将地址分为路和号和弄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_list=[]\n",
    "for addr in sql_Estate['EstateAddress']:\n",
    "    try:\n",
    "        word_list=list(jieba.cut(addr,cut_all=False,HMM=False))\n",
    "        flag,word_str=add_road(word_list)\n",
    "        if flag==1:\n",
    "            road_list.append(word_str)\n",
    "        else:\n",
    "            #非路号，而是小区\n",
    "    #         print(addr)\n",
    "            try:\n",
    "                sp_comm=addr.split(' ')\n",
    "                road_list.append(None)\n",
    "#                 road_list.append(sp_comm[1])\n",
    "            except:\n",
    "#                 print(addr)\n",
    "                road_list.append(None)\n",
    "    except:\n",
    "        road_list.append(None)\n",
    "sql_Estate['road']=pd.Series(data=road_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_reg(addr,alley_list):\n",
    "    try:\n",
    "        reg1=re.compile('(\\d+)-(\\d+)号双')\n",
    "        reg2=re.compile('(\\d+)-(\\d+)双号')\n",
    "        reg3=re.compile('(\\d+)-(\\d+)\\(双\\)号')\n",
    "        reg4=re.compile('(\\d+)-(\\d+)号\\(双\\)')\n",
    "        reg_double=reg1.findall(addr) or reg2.findall(addr) or reg3.findall(addr) or reg4.findall(addr)\n",
    "\n",
    "\n",
    "        reg5=re.compile('(\\d+)-(\\d+)\\(单号\\)')\n",
    "        reg6=re.compile('(\\d+)-(\\d+)单号')\n",
    "        reg7=re.compile('(\\d+)-(\\d+)\\(单\\)号')\n",
    "        reg8=re.compile('(\\d+)-(\\d+)号\\(单\\)')\n",
    "        reg9=re.compile('(\\d+)-(\\d+)\\(单\\)')\n",
    "        reg_single=reg5.findall(addr) or reg6.findall(addr) or reg7.findall(addr) or reg8.findall(addr) or reg9.findall(addr)\n",
    "\n",
    "        reg10=re.compile('路(\\d+)-(\\d+)号')\n",
    "        reg11=re.compile('街(\\d+)-(\\d+)号')\n",
    "        reg_continuous= reg10.findall(addr) or reg11.findall(addr)\n",
    "\n",
    "        reg12=re.compile('路(\\d+)弄')\n",
    "        reg13=re.compile('路(\\d+)号')\n",
    "        reg14=re.compile('街(\\d+)弄')\n",
    "        reg15=re.compile('街(\\d+)号')\n",
    "        reg16=re.compile('路(\\d+)弄\\d+号')\n",
    "        reg17=re.compile('道(\\d+)号')\n",
    "        reg18=re.compile('村(\\d+)号')\n",
    "        reg19=re.compile('村(\\d+)弄')\n",
    "        reg29=re.compile('道(\\d+)弄')\n",
    "        reg_base=reg12.findall(addr) or reg13.findall(addr) or reg14.findall(addr) or reg15.findall(addr) or reg16.findall(addr) or reg17.findall(addr) or reg18.findall(addr) or reg19.findall(addr) or reg29.findall(addr) \n",
    "\n",
    "        reg20=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg21=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg22=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg23=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg24=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg25=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg26=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg27=re.compile('(\\d+)-(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg28=re.compile('(\\d+)-(\\d+)-(\\d+)')\n",
    "        reg_random=reg20.findall(addr) or reg21.findall(addr) or reg23.findall(addr) or reg24.findall(addr) or reg25.findall(addr) or reg26.findall(addr) or reg27.findall(addr) or reg28.findall(addr)\n",
    "\n",
    "\n",
    "        reg30=re.compile('\\d+')\n",
    "        reg_other=reg30.findall(addr)\n",
    "\n",
    "        if len(reg_double)>0 and int(reg_double[0][0])<int(reg_double[0][1]):\n",
    "                    res=[str(i) for i in range(int(reg_double[0][0]),int(reg_double[0][1])+1,2)]\n",
    "                    alley=','.join(res)\n",
    "                    alley_list.append(alley)\n",
    "#                     print(reg_double,addr,'=========',alley)\n",
    "\n",
    "        elif len(reg_single)>0 and int(reg_single[0][0])<int(reg_single[0][1]):\n",
    "                    res=[str(i) for i in range(int(reg_single[0][0]),int(reg_single[0][1])+1,2)]\n",
    "                    alley=','.join(res)\n",
    "                    alley_list.append(alley)\n",
    "#                     print(reg_single,addr,'$$$$$$$',alley)\n",
    "\n",
    "        elif len(reg_continuous)>0 and int(reg_continuous[0][0])<int(reg_continuous[0][1]):\n",
    "                    res=[str(i) for i in range(int(reg_continuous[0][0]),int(reg_continuous[0][1])+1)]\n",
    "                    alley=','.join(res)\n",
    "                    alley_list.append(alley)\n",
    "#                     print(reg_continuous,addr,'*******',alley)\n",
    "        elif len(reg_random)>0:\n",
    "            res=[str(i) for i in reg_random[0]]\n",
    "            alley=','.join(res)\n",
    "            alley_list.append(alley)\n",
    "#             print(reg_random,addr,'@@@@@@@@@',alley)\n",
    "        elif len(reg_base)>0:\n",
    "            res=[str(i) for i in reg_base]\n",
    "            alley=','.join(res)\n",
    "            alley_list.append(alley)\n",
    "#             print(reg_base,addr,'!!!!!!!!!!!!',alley)\n",
    "        elif len(reg_other)>0:\n",
    "            res=[str(i) for i in reg_other]\n",
    "            alley=','.join(res)\n",
    "            alley_list.append(alley)\n",
    "#             print(reg_base,addr,'###########',alley)\n",
    "        else:\n",
    "            alley_list.append(None)\n",
    "    except:\n",
    "        alley_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alley_list=[]\n",
    "for addr in sql_Estate['EstateAddress']:\n",
    "    which_reg(addr,alley_list)\n",
    "sql_Estate['alley']=pd.Series(data=alley_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将路拆开，执行一次\n",
    "sql_Estate=sql_Estate.drop('road', axis=1).join(\n",
    "    sql_Estate['road'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('road'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将号拆开，执行一次\n",
    "sql_Estate=sql_Estate.drop('alley', axis=1).join(\n",
    "    sql_Estate['alley'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).rename('alley'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_Estate.drop_duplicates(inplace=True)\n",
    "sql_Estate['road_']=sql_Estate['road']+sql_Estate['alley']\n",
    "sql_Estate.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40602, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20901, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sql_Estate.shape)\n",
    "display(usefull_addr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EstateId</th>\n",
       "      <th>EstateAreaName</th>\n",
       "      <th>EstateAddress</th>\n",
       "      <th>EstateOtherAddress</th>\n",
       "      <th>road</th>\n",
       "      <th>alley</th>\n",
       "      <th>road_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22388</td>\n",
       "      <td>正峰苑</td>\n",
       "      <td>申北路150-154号</td>\n",
       "      <td>申北路134-138号,申北路162号,申北路142-146号,申北路130号,申北路168...</td>\n",
       "      <td>申北路</td>\n",
       "      <td>150</td>\n",
       "      <td>申北路150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EstateId EstateAreaName EstateAddress  \\\n",
       "0     22388            正峰苑   申北路150-154号   \n",
       "\n",
       "                                  EstateOtherAddress road alley   road_  \n",
       "0  申北路134-138号,申北路162号,申北路142-146号,申北路130号,申北路168...  申北路   150  申北路150  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_Estate.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging=sql_Estate[sql_Estate['road_'].notnull()].merge(usefull_addr[usefull_addr['road_'].notnull()],how='inner',left_on='road_',right_on='road_').drop_duplicates(subset=['EstateId','PropertyAddress','PropertyCommunity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine=create_engine('mssql+pymssql://tw_user:123456@10.55.5.215/TWSpider')\n",
    "merging.drop_duplicates(inplace=True)\n",
    "# merging.to_sql('mapping',engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging.drop(labels=['road_x','alley_x','road_','alley_y','road_y'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_mapping=pd.DataFrame(np.concatenate((merging.values,comm_mapping.values)),columns=merging.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_mapping.to_sql('mapping',engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下测试用  d为没有匹配的小区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=extract_comm.loc[:,['PropertyCommunity','PropertyAddress']].drop_duplicates()\n",
    "b=comm_mapping.loc[:,['PropertyCommunity','PropertyAddress']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.fillna(value='',inplace=True)\n",
    "b.fillna(value='',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['mapp']=a['PropertyCommunity']+a['PropertyAddress']\n",
    "b['mapp']=b['PropertyCommunity']+b['PropertyAddress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a.merge(b,how='inner',left_on='mapp',right_on='mapp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "notmapp_set=set(a['mapp'].tolist())-set(c['mapp'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=a.query(\"mapp in @notmapp_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyCommunity</th>\n",
       "      <th>PropertyAddress</th>\n",
       "      <th>mapp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>朗诗未来树</td>\n",
       "      <td>浦东-祝桥-外环外</td>\n",
       "      <td>朗诗未来树浦东-祝桥-外环外</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>西班牙名园</td>\n",
       "      <td>闵行-梅陇-中环至外环近1号线莲花路站</td>\n",
       "      <td>西班牙名园闵行-梅陇-中环至外环近1号线莲花路站</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>九城湖滨国际</td>\n",
       "      <td>松江-九亭-外环外</td>\n",
       "      <td>九城湖滨国际松江-九亭-外环外</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>城开珑庭</td>\n",
       "      <td>闵行-梅陇-中环至外环</td>\n",
       "      <td>城开珑庭闵行-梅陇-中环至外环</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>上海阳城</td>\n",
       "      <td>闵行-梅陇-中环至外环近1号线外环路站</td>\n",
       "      <td>上海阳城闵行-梅陇-中环至外环近1号线外环路站</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305670</th>\n",
       "      <td>新建路82弄(浦东)</td>\n",
       "      <td></td>\n",
       "      <td>新建路82弄(浦东)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305671</th>\n",
       "      <td>川北小区</td>\n",
       "      <td></td>\n",
       "      <td>川北小区</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305674</th>\n",
       "      <td>亿阳戴家新苑</td>\n",
       "      <td></td>\n",
       "      <td>亿阳戴家新苑</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305681</th>\n",
       "      <td>建发江湾萃</td>\n",
       "      <td></td>\n",
       "      <td>建发江湾萃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305741</th>\n",
       "      <td>马陆街248弄</td>\n",
       "      <td></td>\n",
       "      <td>马陆街248弄</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PropertyCommunity      PropertyAddress                      mapp\n",
       "7                  朗诗未来树            浦东-祝桥-外环外            朗诗未来树浦东-祝桥-外环外\n",
       "15                 西班牙名园  闵行-梅陇-中环至外环近1号线莲花路站  西班牙名园闵行-梅陇-中环至外环近1号线莲花路站\n",
       "21                九城湖滨国际            松江-九亭-外环外           九城湖滨国际松江-九亭-外环外\n",
       "28                  城开珑庭          闵行-梅陇-中环至外环           城开珑庭闵行-梅陇-中环至外环\n",
       "29                  上海阳城  闵行-梅陇-中环至外环近1号线外环路站   上海阳城闵行-梅陇-中环至外环近1号线外环路站\n",
       "...                  ...                  ...                       ...\n",
       "305670        新建路82弄(浦东)                                     新建路82弄(浦东)\n",
       "305671              川北小区                                           川北小区\n",
       "305674            亿阳戴家新苑                                         亿阳戴家新苑\n",
       "305681             建发江湾萃                                          建发江湾萃\n",
       "305741           马陆街248弄                                        马陆街248弄\n",
       "\n",
       "[18282 rows x 3 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extract_comm': 0.018223823979496956, 'sql_Estate': 0.0012100953608751297, 'not_mapping': 0.0007939022034406662, 'usefull_addr': 0.0007786974310874939, 'has_addr': 0.0006459709256887436, 'comm_mapping': 0.00036182254552841187, 'useless_addr': 0.0003140270709991455, 'hasnot_addr': 0.00020710378885269165, 'comm_merge_addr': 0.00010839104652404785, 'fourth_comm': 0.00010250508785247803, '_60': 1.6763806343078613e-06}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "## 通过变量名获得变量，并计算内存（只计算dataFrame变量的内存）\n",
    "def get_memory(name,dict_all):\n",
    "    try:\n",
    "        dict_all[name] = sys._getframe().f_back.f_locals[name].memory_usage().sum() / 1024 ** 2 / 1024\n",
    "    except:\n",
    "        a = 1\n",
    " \n",
    "dict_all = {}\n",
    "for i in dir():\n",
    "    get_memory(i, dict_all)\n",
    "    \n",
    "##对dict_all进行逆排序\n",
    "def sort_dict(dict_words):\n",
    "    keys = dict_words.keys()\n",
    "    values = dict_words.values()\n",
    "    list_one = [(key, val) for key, val in zip(keys, values)]\n",
    "    list_sort = sorted(list_one, key=lambda x: x[1], reverse=True)\n",
    "    dict_return = {}\n",
    "    for (key,value) in list_sort:\n",
    "        dict_return[key] = value\n",
    "    return dict_return\n",
    " \n",
    "dict_return = sort_dict(dict_all)\n",
    "print(dict_return)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
